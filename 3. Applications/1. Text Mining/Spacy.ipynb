{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDamda+fwb97+dR/+xMNeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dforouzanfar/Machine_Learning/blob/master/3.%20Applications/1.%20Text%20Mining/Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# spaCy"
      ],
      "metadata": {
        "id": "WPyC7Lbp-Etw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy is an open-source Python library for advanced NLP. It is designed to handle large-scale NLP tasks efficiently and comes with pre-trained statistical models and deep learning integration.\n",
        "\n",
        "**Key Features**\n",
        "1. Tokenization\n",
        "2. Named Entity Recognition - NER\n",
        "3. Part-of-Speech (POS) Tagging\n",
        "4. Dependency Parsing - relationships between words.\n",
        "5. Word Vectors - word embeddings\n",
        "6. Custom Pipelines\n",
        "7. Multi-language Support\n",
        "\n",
        "**Applications**\n",
        "1. Text classification\n",
        "2. Information extraction\n",
        "3. Summarization\n",
        "4. Sentiment analysis\n",
        "5. Translation"
      ],
      "metadata": {
        "id": "INIv6Gvd-YtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import spacy\n",
        "except:\n",
        "  !pip install spacy\n",
        "  !python -m spacy download en\n",
        "  import spacy"
      ],
      "metadata": {
        "id": "4cOqfSP3-Rfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tokenization"
      ],
      "metadata": {
        "id": "jkvtAb9oJQow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spacy.blank(name)"
      ],
      "metadata": {
        "id": "OBmoKSHLNXXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a blank English spaCy pipeline\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "nlp.pipeline # we call spacy.blank, so we don't have anything except tokenizer in the pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncqDJL5nJZes",
        "outputId": "15123ea6-ed1c-4e7f-f9c3-ef23f2809f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing a text string to extract patterns and insights\n",
        "doc = nlp(\"Text mining is the process of extracting   meaningful patterns and insights from text data.\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w9ikhYRVFTw",
        "outputId": "c07694b8-ac10-4a88-8abf-35a8b9be4a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text mining is the process of extracting   meaningful patterns and insights from text data."
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mWkrypxJ6C5",
        "outputId": "8f6d245a-9dfa-4282-f0da-a5d6bfde9a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text\n",
            "mining\n",
            "is\n",
            "the\n",
            "process\n",
            "of\n",
            "extracting\n",
            "  \n",
            "meaningful\n",
            "patterns\n",
            "and\n",
            "insights\n",
            "from\n",
            "text\n",
            "data\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = doc[1]\n",
        "token.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "31pzn5gXOMeq",
        "outputId": "360f0435-7fc5-477b-8a35-602d9683a9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mining'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Token Attributes"
      ],
      "metadata": {
        "id": "eaSta2dEWY2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are numerous operations we can perform on each token, leveraging its attributes. Some of the most commonly used attributes include:\n",
        "* is_alpha\n",
        "* is_currency\n",
        "* is_digit\n",
        "* is_space\n",
        "* lemma\n",
        "* like_email\n",
        "* like_url\n",
        "\n",
        "you can access to all the methods with ```dir(token)```"
      ],
      "metadata": {
        "id": "PcouOmW_R0-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token = doc[7]\n",
        "token, token.is_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1TFjINOP07q",
        "outputId": "56824c3c-7944-4a2e-8173-ed95da95b1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(  , True)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if not token.is_space and not token.is_punct:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK-hVyy8RYzJ",
        "outputId": "21ce708b-ad3b-4f0f-bc34-c65c3652171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text\n",
            "mining\n",
            "is\n",
            "the\n",
            "process\n",
            "of\n",
            "extracting\n",
            "meaningful\n",
            "patterns\n",
            "and\n",
            "insights\n",
            "from\n",
            "text\n",
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also select a span of the sentence\n",
        "span = doc[:5]\n",
        "span"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2rcYvBRYw9",
        "outputId": "69b5facd-d27e-47d3-ab07-b31bf42aea4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text mining is the process"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding a pipe\n",
        "\n",
        "Visit spaCy's doc page to explore more: https://spacy.io/usage/processing-pipelines"
      ],
      "metadata": {
        "id": "EObvXhNEXvWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2hNMBI0RYuI",
        "outputId": "834bc9ae-1aa5-41f3-951e-af6e86c06f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7ba21d4cacc0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Text mining is the process of extracting meaningful patterns and insights from text data. NLP is a branch of artificial intelligence that focuses on the interaction between computers and human language.\")\n",
        "c = 1\n",
        "for sentence in doc.sents:\n",
        "    print(f\"sentence {c} is:\\n{sentence}\\nThe words in this sentence are: \")\n",
        "    for word in sentence:\n",
        "      if not word.is_punct:\n",
        "        print(word)\n",
        "    c += 1\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXXHdFP5RYri",
        "outputId": "2f9746fa-4706-462b-d5b4-7a31236742d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence 1 is:\n",
            "Text mining is the process of extracting meaningful patterns and insights from text data.\n",
            "The words in this sentence are: \n",
            "Text\n",
            "mining\n",
            "is\n",
            "the\n",
            "process\n",
            "of\n",
            "extracting\n",
            "meaningful\n",
            "patterns\n",
            "and\n",
            "insights\n",
            "from\n",
            "text\n",
            "data\n",
            "\n",
            "\n",
            "sentence 2 is:\n",
            "NLP is a branch of artificial intelligence that focuses on the interaction between computers and human language.\n",
            "The words in this sentence are: \n",
            "NLP\n",
            "is\n",
            "a\n",
            "branch\n",
            "of\n",
            "artificial\n",
            "intelligence\n",
            "that\n",
            "focuses\n",
            "on\n",
            "the\n",
            "interaction\n",
            "between\n",
            "computers\n",
            "and\n",
            "human\n",
            "language\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Named Entity Recognition"
      ],
      "metadata": {
        "id": "Sa7AYzbq3ciH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy.load()\n",
        "\n",
        "We can also load a pretrained model using ```spacy.load()```.  \n",
        "To explore available models, visit spaCy's models page: https://spacy.io/models/en"
      ],
      "metadata": {
        "id": "JNMAcYKvRnOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a blank English spaCy pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDo8k9M8RYTT",
        "outputId": "e361f354-dbfe-446f-b841-8d80b6cc8eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing a text string to extract patterns and insights\n",
        "doc = nlp(\"Text mining is the process of extracting meaningful patterns and insights from text data. NLP is a branch of artificial intelligence that focuses on the interaction between computers and human language.\")"
      ],
      "metadata": {
        "id": "N1NlARk9VX2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Tokenization\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-kiy9avRg8K",
        "outputId": "bda08ef6-fbe5-4ed7-f641-dbcd7af1b46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text mining is the process of extracting meaningful patterns and insights from text data.\n",
            "NLP is a branch of artificial intelligence that focuses on the interaction between computers and human language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"As of January 2025 Apple has a market cap of $3.580 Trillion USD.\")\n",
        "doc.ents"
      ],
      "metadata": {
        "id": "vnTH83ac6QCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(f\"{ent.text:<15} | {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv5WUqjB6QAR",
        "outputId": "7cd4b280-8066-4dac-8793-33de8eeb5d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "January 2025    | DATE\n",
            "Apple           | ORG\n",
            "$3.580 Trillion | MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use displacy.render for a well-structured visualization\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EhdqIFUw6P9u",
        "outputId": "598a7bec-b7ee-4c40-9689-0fcd9b9aabe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    January 2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " has a market cap of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $3.580 Trillion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " USD.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Part of Speech Tagger"
      ],
      "metadata": {
        "id": "0dwJ6n9S3KJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Batman patrols Gotham City under the cover of darkness, ensuring justice prevails against its relentless wave of crime.\")"
      ],
      "metadata": {
        "id": "dd8YboEK3Bkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(f\"{token.text:<10} | {token.pos_:<6} | {spacy.explain(token.pos_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz1FcpvX8fwt",
        "outputId": "addd746d-bbe1-4aa4-ebc4-2291d1b77c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batman     | PROPN  | proper noun\n",
            "patrols    | VERB   | verb\n",
            "Gotham     | PROPN  | proper noun\n",
            "City       | PROPN  | proper noun\n",
            "under      | ADP    | adposition\n",
            "the        | DET    | determiner\n",
            "cover      | NOUN   | noun\n",
            "of         | ADP    | adposition\n",
            "darkness   | NOUN   | noun\n",
            ",          | PUNCT  | punctuation\n",
            "ensuring   | VERB   | verb\n",
            "justice    | NOUN   | noun\n",
            "prevails   | VERB   | verb\n",
            "against    | ADP    | adposition\n",
            "its        | PRON   | pronoun\n",
            "relentless | ADJ    | adjective\n",
            "wave       | NOUN   | noun\n",
            "of         | ADP    | adposition\n",
            "crime      | NOUN   | noun\n",
            ".          | PUNCT  | punctuation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Stemming & Lemmatization\n",
        "**Stemming**: Stemming is a crude heuristic process that removes word suffixes to reduce words to a common root\n",
        "* playing, played, plays --> play\n",
        "* eating, eats --> eat\n",
        "* ate --> ate\n",
        "\n",
        "**Lemmatization**: Lemmatization is more sophisticated and involves reducing words to their base or dictionary form\n",
        "* playing, played, plays --> play\n",
        "* **ate** --> eat"
      ],
      "metadata": {
        "id": "oLo7VxdD_8cD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "Gv5dWKI9GKhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "co4ws-bR8v6k"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"eating eats eat ate adjustable ability meeting\")"
      ],
      "metadata": {
        "id": "ocTCz1lTBfxZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(f\"Token: {token.text:<10} | Lemma: {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmeMdUknBrbC",
        "outputId": "e7c6d849-3b07-4bd4-8a7c-f63a37e7d84d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: eating     | Lemma: eat\n",
            "Token: eats       | Lemma: eat\n",
            "Token: eat        | Lemma: eat\n",
            "Token: ate        | Lemma: eat\n",
            "Token: adjustable | Lemma: adjustable\n",
            "Token: ability    | Lemma: ability\n",
            "Token: meeting    | Lemma: meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customizing lemmatizer"
      ],
      "metadata": {
        "id": "gTrBOH-3FVDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dad, let's go out! Papa, don't say no\")\n",
        "for token in doc:\n",
        "  if token.text == 'Dad' or token.text == 'Papa':\n",
        "    print(f\"Token: {token.text:<5} | Lemma: {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaU_RpKHEcCs",
        "outputId": "cdc34d81-b06b-494f-d8ce-cfafc76d822d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Dad   | Lemma: Father\n",
            "Token: Papa  | Lemma: Father\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_r = nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "attribute_r.add(\n",
        "    [\n",
        "        [\n",
        "            {\"TEXT\":\"Dad\"}\n",
        "        ],\n",
        "        [\n",
        "            {\"TEXT\":\"Papa\"}\n",
        "        ]\n",
        "    ],\n",
        "    {\"LEMMA\":\"Father\"}\n",
        "  )"
      ],
      "metadata": {
        "id": "dg7Htpu6D3fV"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if token.text == 'Dad' or token.text == 'Papa':\n",
        "    print(f\"Token: {token.text:<5} | Lemma: {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZspB_bjFtnZ",
        "outputId": "75f647d7-5462-4e86-a33d-0e54feae3a36"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Dad   | Lemma: Father\n",
            "Token: Papa  | Lemma: Father\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming\n",
        "With spaCy we can't get the stemm of the words. We can use NLTK instead."
      ],
      "metadata": {
        "id": "sNkl03KjC9wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import nltk\n",
        "  from nltk.stem import PorterStemmer\n",
        "except:\n",
        "  !pip install nltk\n",
        "  import nltk\n",
        "  from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "giC6YWebDRqv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "Dl6BBR3oDMIC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "  print(f\"{word:<10} | {stemmer.stem(word)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy1YRhcXDuAe",
        "outputId": "1abcf22f-95b0-40ab-b21d-bb2a1c8f25cd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating     | eat\n",
            "eats       | eat\n",
            "eat        | eat\n",
            "ate        | ate\n",
            "adjustable | adjust\n",
            "ability    | abil\n",
            "meeting    | meet\n"
          ]
        }
      ]
    }
  ]
}